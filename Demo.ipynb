{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348fedf4-c2c9-4ea8-b6c6-6e27c6eabf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import exposenn.ontology\n",
    "import exposenn.models\n",
    "import exposenn.data\n",
    "import exposenn.trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db2720",
   "metadata": {},
   "source": [
    "# Формирование объяснимой архитектуры с логическим блоком\n",
    "\n",
    "Для формирования объяснимой архитектуры необходимо загрузить онтологию и определить, какие из концептов, релевантных целевому, должны фигурировать в объяснениях. Это должны быть те же самые концепты, что присутствуют в разметке.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4177fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    java -Xmx2000M -cp C:\\Users\\aaagafonov\\anaconda3\\envs\\onto-xai\\Lib\\site-packages\\owlready2\\hermit;C:\\Users\\aaagafonov\\anaconda3\\envs\\onto-xai\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/AAAGAF~1/AppData/Local/Temp/tmp6wc38csm\n",
      "* Owlready2 * HermiT took 2.7379350662231445 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "# Загрузить онтологию в формате RDF/XML\n",
    "# (загрузка производится с помощью owlready2, а эта библиотека полноценно\n",
    "# поддерживает только RDF/XML)\n",
    "ontology = exposenn.ontology.MockOntologyAnalyzer('ontologies/demo.rdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e79a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(demo.Class1, [demo.AorB, demo.C, demo.AorB & demo.C, demo.A, demo.B])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предположим, целевым классом для задачи является класс, который в онтологии\n",
    "# называется Class1.\n",
    "# Используя онтологию, можно выяснить, какие классы целесообразно включать в\n",
    "# онтолого-ориентированное объяснение (какие классы используются в определении\n",
    "# Class1):\n",
    "target_concept = ontology.get_concept('Class1')\n",
    "relevant_concepts = ontology.get_relevant('Class1')\n",
    "\n",
    "target_concept, relevant_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07acee",
   "metadata": {},
   "source": [
    "Теоретически, все концепты из `relevant_concepts` могли бы найти свое\n",
    "место в объяснимой архитектуре. Однако в нее целесообразно включать только \n",
    "такие концепты, для которых в принципе есть метки, потому что процесс обучения\n",
    "(одна из его фаз или одна из используемых ЦФ) предполагает, что обучение производится с известными метками по промежуточным концептам (иначе добиться того, чтобы за определенный концепт отвечал определенный выход, по видимому, невозможно).\n",
    "\n",
    "Стандартным форматом разметки является `csv`-файл и для него следует задать соответствие между названиями столбцов и концептами онтологии. После этого следует \"проредить\" полный список релевантных концептов, оставив только те, для которых есть реальные метки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d03b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>classC</th>\n",
       "      <th>classD</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img  A  B  classC  classD  E  F  tgt\n",
       "0  001.png  1  0       1       0  0  0    1\n",
       "1  002.png  1  0       1       0  0  0    1\n",
       "2  003.png  1  0       1       0  0  1    1\n",
       "3  004.png  1  0       1       0  0  1    1\n",
       "4  005.png  1  1       1       0  0  1    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/demo.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c6e9f-dcce-4b53-aab6-e4ec5c025412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>classC</th>\n",
       "      <th>classD</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>tgt</th>\n",
       "      <th>AorB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       img  A  B  classC  classD  E  F  tgt  AorB\n",
       "0  001.png  1  0       1       0  0  0    1     1\n",
       "1  002.png  1  0       1       0  0  0    1     1\n",
       "2  003.png  1  0       1       0  0  1    1     1\n",
       "3  004.png  1  0       1       0  0  1    1     1\n",
       "4  005.png  1  1       1       0  0  1    1     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AorB'] = df['A'] | df['B']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99f9524-1733-478f-9ec7-e2f79444331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/demo_extended.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90da4c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка отображения \"имя колонки\"->\"концепт онтологии\"\n",
    "column_to_concept = {\n",
    "    'A': ontology.get_concept('A'),\n",
    "    'B': ontology.get_concept('B'),\n",
    "    'AorB': ontology.get_concept('AorB'),\n",
    "    'classC': ontology.get_concept('C'),\n",
    "    'tgt': ontology.get_concept('Class1')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfcd4e8",
   "metadata": {},
   "source": [
    "Процесс настройки такого отображения может быть и, в определенном роде, двухсторонним. Например, среди релевантных концептов есть `AorB` и если мы понимаем, как он был получен из `A` и `B` то мы можем добавить вычисляемую колонку и связать ее с соответствующим концептом.\n",
    "\n",
    "Далее, оставляем только те концепты, которые будут фигурировать в архитектуре:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c402a791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[demo.AorB, demo.C, demo.A, demo.B]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts = [x for x in relevant_concepts if x in column_to_concept.values()]\n",
    "concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbf3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = torchvision.models.resnet18()\n",
    "# Мы будем обучать задачу бинарной классификации, поэтому\n",
    "# подправим количество выходов:\n",
    "backbone.fc = nn.Linear(512, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8757d3",
   "metadata": {},
   "source": [
    "Сеть интерпретации может \"подключаться\" к разным слоям основной сети. Спецификация такого подключения описывается набором пар (слой - \"коннектор\"), где слой - слой базовой сети, а \"коннектор\" какой-то `nn.Module`, который будет на вход принимать результат работы соответствующего слоя базовой сети, а на выходе формировать тензор, попадающий на вход сети интерпретации. Для всех архитектур сетей интерпретации, которые рассматривались в ходе проекта, этот тензор должен быть одномерным (потом такие одномерные тензоры конкатенируются и \"пропускаются\" через набор полносвязных слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596a757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connectors = [\n",
    "#     (backbone.layer3,  exposenn.models.GlobalAvgPool2dConnector(256)),\n",
    "#     (backbone.avgpool, nn.Flatten(-3))\n",
    "# ]\n",
    "\n",
    "from exposenn.utils import create_connectors\n",
    "\n",
    "connectors, total_features = create_connectors(backbone, [nn.Conv2d, nn.BatchNorm2d])\n",
    "\n",
    "model = exposenn.models.MLPInterpretationNetwork(\n",
    "    backbone,\n",
    "    connectors,\n",
    "    [total_features, len(concepts)]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "126fc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, conc_hat = model(torch.zeros((5, 3, 40, 40)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a401b33-a09b-4a7b-b7b1-7fa9e94a8354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4994, 0.5020, 0.4975, 0.5009],\n",
       "        [0.4994, 0.5020, 0.4975, 0.5009],\n",
       "        [0.4994, 0.5020, 0.4975, 0.5009],\n",
       "        [0.4994, 0.5020, 0.4975, 0.5009],\n",
       "        [0.4994, 0.5020, 0.4975, 0.5009]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conc_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b4ea443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]), torch.Size([5, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape, conc_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dca4640",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "Предполагается поддержка двух подходов к обучению:\n",
    "\n",
    "- обучение в рамках одного цикла со сложной функцией потерь, учитывающей разные компоненты;\n",
    "- обучение на нескольких наборах с разными функциями (когда, например, прошли по образцам,\n",
    "  размеченным только на целевой класс, потом по образцам, размеченным на концепты, и т.п.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a2fe6",
   "metadata": {},
   "source": [
    "## Обучение без учета логических ограничений\n",
    "\n",
    "Здесь важно только сопоставление целевого класса и всех меток концептов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a22f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обратное отображение концептов в колонки имеющегося набора данных\n",
    "concept_to_column = {\n",
    "    concept: column\n",
    "    for column, concept in column_to_concept.items()\n",
    "        if concept in concepts\n",
    "}\n",
    "# список названий колонок, которые имеет смысл использовать\n",
    "# при обучении\n",
    "concept_columns = list(concept_to_column.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604f23b0-b0d6-4583-9d9a-8e201d518f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'AorB', 'classC']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91c59a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{demo.A: 'A', demo.B: 'B', demo.AorB: 'AorB', demo.C: 'classC'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_to_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2d5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = exposenn.data.AnnotatedImagesDataset('data/demo_extended.csv',   # файл с аннотациями\n",
    "                                               'data/img/',       # директория с картинками\n",
    "                                               'img',             # колонка с именем файла\n",
    "                                               'tgt',             # колонка с целевой меткой\n",
    "                                               concept_columns,   # список с колонками-концептами\n",
    "                                               transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2d6c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " tensor([1, 0, 1, 1], dtype=torch.int8),\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04cd10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a48bc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exposenn.loss import AdditiveMultipartLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "288f5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_fn = AdditiveMultipartLoss(\n",
    "    concepts_loss_fn = torch.nn.BCELoss(),\n",
    "    target_loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    ")\n",
    "history = exposenn.trainers.train(model, dataloader, loss_fn, optim, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59d2beb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 5.956979751586914},\n",
       " {'train_loss': 2.53704833984375},\n",
       " {'train_loss': 1.8345041275024414},\n",
       " {'train_loss': 0.9338347911834717},\n",
       " {'train_loss': 0.6312347650527954}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68710a7a",
   "metadata": {},
   "source": [
    "## Обучение c учетом логических ограничений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a5c366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('->', demo.A, demo.AorB),\n",
       " ('->', demo.B, demo.AorB),\n",
       " ('->', demo.Class1, demo.AorB),\n",
       " ('->', demo.Class1, demo.C),\n",
       " ('->', demo.Class1, demo.AorB & demo.C)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statements = ontology.get_relevant_statements(relevant_concepts + [target_concept])\n",
    "statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3e4a57a-59b9-4bc3-81e9-fa735476e698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[demo.A, demo.B, demo.AorB, demo.C]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(concept_to_column.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "351f841e-b452-4950-a8ba-95aa1381a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exposenn.loss import SemanticLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f2a041-e719-443d-9ec5-eb66fd8cf15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo.Class1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_concept['tgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5960877a-cf7e-4ccd-8504-7ce58927315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed constraint\n",
      "Parsed constraint\n",
      "converting to cnf\n",
      "writing to DIMACS\n",
      "Parsed constraint\n",
      "Parsed constraint\n",
      "Parsed constraint\n",
      "Parsed constraint\n",
      "converting to cnf\n",
      "writing to DIMACS\n"
     ]
    }
   ],
   "source": [
    "# без учёта целевого класса\n",
    "semantic_loss_without_tgt = SemanticLoss(list(concept_to_column.keys()), statements)\n",
    "\n",
    "# с учётом целевого класса\n",
    "semantic_loss_with_tgt = SemanticLoss(list(concept_to_column.keys()), statements, column_to_concept['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebf9fcc4-35c4-4487-b8c4-916650eb384e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4707, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_loss_without_tgt(conc_hat, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11f31b66-1ee3-40c8-b5c5-08061a13c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_fn = AdditiveMultipartLoss(\n",
    "    concepts_loss_fn = semantic_loss_with_tgt,\n",
    "    target_loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    ")\n",
    "history = exposenn.trainers.train(model, dataloader, loss_fn, optim, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97987964-a847-4562-9244-9bf1b371b696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 2.310514450073242},\n",
       " {'train_loss': 0.8070630431175232},\n",
       " {'train_loss': 0.6123401522636414},\n",
       " {'train_loss': 0.22492147982120514},\n",
       " {'train_loss': 0.10437925159931183}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c3c065",
   "metadata": {},
   "source": [
    "# Два слоя: нейронная сеть и (объяснимая) логистическая регрессия\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
